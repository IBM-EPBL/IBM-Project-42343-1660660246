{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adcf7646",
   "metadata": {},
   "source": [
    "# Sprint 2\n",
    "\n",
    "## Team ID: PNT2022TMID43387\n",
    "\n",
    "###  Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfd173cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow #both ML and DL for computation\n",
    "from tensorflow.keras.datasets import mnist #mnist dataset\n",
    "from tensorflow.keras.models import Sequential #plain stack of layers\n",
    "from tensorflow.keras import layers #A Layer consists of a tensor- in tensor-out computat ion funct ion\n",
    "from tensorflow.keras.layers import Dense, Flatten #dense and flatten layers\n",
    "from tensorflow.keras.layers import Conv2D #onvoLutiona l Layer\n",
    "from tensorflow.keras.layers import MaxPooling2D \n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from keras.optimizers import Adam #optimizer\n",
    "from keras. utils import np_utils #used for one-hot encoding\n",
    "import matplotlib.pyplot as plt   #used for data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb53b2f",
   "metadata": {},
   "source": [
    "### Data preprocessing - Sprint 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a57e9649",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
    "\n",
    "#CNN expected format: (batch,height,width,channel)\n",
    "x_train=x_train.reshape(60000,28,28,1).astype('float32')\n",
    "x_test=x_test.reshape(10000,28,28,1).astype('float32')\n",
    "no_of_classes=10\n",
    "y_train=np_utils.to_categorical(y_train,no_of_classes) #converts output to binary format\n",
    "y_test=np_utils.to_categorical(y_test,no_of_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cddd7a",
   "metadata": {},
   "source": [
    "### Add CNN Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37583249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = 3, activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(32, kernel_size = 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e259ec",
   "metadata": {},
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b90717fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile model\n",
    "model.compile(loss= 'categorical_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d99396d",
   "metadata": {},
   "source": [
    "Compilation requires 3 arguments: an optimizer, a loss function, and a list of metrics.\n",
    "In our project, we have 2 classes in the output, so the loss is binary_crossentropy.\n",
    "If you have more than two classes in output put “loss = categorical_cross entropy”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bce4ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0c3af3",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5721e18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 46s 25ms/step - loss: 0.0314 - accuracy: 0.9913 - val_loss: 0.0258 - val_accuracy: 0.9936\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0289 - accuracy: 0.9923 - val_loss: 0.0206 - val_accuracy: 0.9946\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 50s 27ms/step - loss: 0.0298 - accuracy: 0.9921 - val_loss: 0.0213 - val_accuracy: 0.9943\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 57s 31ms/step - loss: 0.0259 - accuracy: 0.9933 - val_loss: 0.0210 - val_accuracy: 0.9937\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 59s 31ms/step - loss: 0.0250 - accuracy: 0.9933 - val_loss: 0.0256 - val_accuracy: 0.9932\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 58s 31ms/step - loss: 0.0253 - accuracy: 0.9934 - val_loss: 0.0264 - val_accuracy: 0.9934\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 59s 31ms/step - loss: 0.0238 - accuracy: 0.9936 - val_loss: 0.0242 - val_accuracy: 0.9936\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 60s 32ms/step - loss: 0.0212 - accuracy: 0.9940 - val_loss: 0.0291 - val_accuracy: 0.9927\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 62s 33ms/step - loss: 0.0221 - accuracy: 0.9944 - val_loss: 0.0270 - val_accuracy: 0.9938\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 59s 31ms/step - loss: 0.0200 - accuracy: 0.9947 - val_loss: 0.0221 - val_accuracy: 0.9938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14d5dfcb280>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a194212a",
   "metadata": {},
   "source": [
    "Arguments:\n",
    "steps_per_epoch : it specifies the total number of steps taken from the generator as soon as one epoch is finished and the next epoch has started. We can calculate the value of steps_per_epoch as the total number of samples in your dataset divided by the batch size.\n",
    "\n",
    "Epochs: an integer and number of epochs we want to train our model for.\n",
    "\n",
    "Validation_data :  \n",
    "an inputs and targets list\n",
    "a generator\n",
    "inputs, targets, and sample_weights list which can be used to evaluate the loss and metrics for any model after any epoch has ended.\n",
    "\n",
    "\n",
    "validation_steps: only if the validation_data is a generator then only this argument can be used. It specifies the total number of steps taken from the generator before it is stopped at every epoch and its value is calculated as the total number of validation data points in your dataset divided by the validation batch size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8d7ad6",
   "metadata": {},
   "source": [
    "### Observing the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1e02db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics(Test loss & Test Accuracy) : \n",
      "[0.022149497643113136, 0.9937999844551086]\n"
     ]
    }
   ],
   "source": [
    "#final evaluation of the model\n",
    "metrics = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Metrics(Test loss & Test Accuracy) : \")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85de749c",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fe2d08b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m prediction\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(x_test[:\u001b[38;5;241m4\u001b[39m])\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(prediction)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "prediction=model.predict(x_test[:4])\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7daa61e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(prediction,axis=1)) #printing labels from first 4 images\n",
    "print(y_test[:4]) #printing the actual labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9983d615",
   "metadata": {},
   "source": [
    "As we already predicted the input from the x_test. According to that by using argmax function here we are printing the labels with high prediction values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5dcdb8",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "406bdb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "model.save('models/mnistCNN1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beff511",
   "metadata": {},
   "source": [
    "The model is saved with .h5 extension as follows:\n",
    "An H5 file is a data file saved in the Hierarchical Data Format (HDF). It contains multidimensional arrays of scientific data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8736b3cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
